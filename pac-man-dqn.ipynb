{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d963ed87",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.002208,
     "end_time": "2025-04-05T17:21:15.249910",
     "exception": false,
     "start_time": "2025-04-05T17:21:15.247702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77a395d7",
   "metadata": {
    "papermill": {
     "duration": 0.001479,
     "end_time": "2025-04-05T17:21:15.253255",
     "exception": false,
     "start_time": "2025-04-05T17:21:15.251776",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install Important Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "242d21f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T17:21:15.257634Z",
     "iopub.status.busy": "2025-04-05T17:21:15.257294Z",
     "iopub.status.idle": "2025-04-05T17:21:20.213528Z",
     "shell.execute_reply": "2025-04-05T17:21:20.212685Z"
    },
    "papermill": {
     "duration": 4.960392,
     "end_time": "2025-04-05T17:21:20.215202",
     "exception": false,
     "start_time": "2025-04-05T17:21:15.254810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting memory_profiler\r\n",
      "  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\r\n",
      "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.29.0)\r\n",
      "Collecting ale-py\r\n",
      "  Downloading ale_py-0.10.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\r\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.5)\r\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\r\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (3.1.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\r\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\r\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\r\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\r\n",
      "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\r\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.0->gymnasium) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.0->gymnasium) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.0->gymnasium) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.0->gymnasium) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.0->gymnasium) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.21.0->gymnasium) (2.4.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.0->gymnasium) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.21.0->gymnasium) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.0->gymnasium) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.21.0->gymnasium) (2024.2.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.19.1)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.21.0->gymnasium) (2024.2.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\r\n",
      "Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\r\n",
      "Downloading ale_py-0.10.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: memory_profiler, ale-py\r\n",
      "Successfully installed ale-py-0.10.2 memory_profiler-0.61.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install memory_profiler psutil gymnasium ale-py tensorflow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24b72373",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-05T17:21:20.221426Z",
     "iopub.status.busy": "2025-04-05T17:21:20.221177Z",
     "iopub.status.idle": "2025-04-05T22:28:53.669090Z",
     "shell.execute_reply": "2025-04-05T22:28:53.668293Z"
    },
    "papermill": {
     "duration": 18453.452436,
     "end_time": "2025-04-05T22:28:53.670377",
     "exception": false,
     "start_time": "2025-04-05T17:21:20.217941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/gymnasium/envs/registration.py:596: UserWarning: \u001b[33mWARN: plugin: shimmy.registration:register_gymnasium_envs raised Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gymnasium/envs/registration.py\", line 594, in load_plugin_envs\n",
      "    fn()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/shimmy/registration.py\", line 304, in register_gymnasium_envs\n",
      "    _register_atari_envs()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/shimmy/registration.py\", line 244, in _register_atari_envs\n",
      "    _register_atari_configs(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/shimmy/registration.py\", line 168, in _register_atari_configs\n",
      "    from ale_py.roms import utils as rom_utils\n",
      "ImportError: cannot import name 'utils' from 'ale_py.roms' (/usr/local/lib/python3.10/dist-packages/ale_py/roms/__init__.py)\n",
      "\u001b[0m\n",
      "  logger.warn(f\"plugin: {plugin.value} raised {traceback.format_exc()}\")\n",
      "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/util.py:55: DeprecationWarning: jax.xla_computation is deprecated. Please use the AOT APIs; see https://jax.readthedocs.io/en/latest/aot.html. For example, replace xla_computation(f)(*xs) with jit(f).lower(*xs).compiler_ir('hlo'). See CHANGELOG.md for 0.4.30 for more examples.\n",
      "  from jax import xla_computation as _xla_computation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using configuration (RAM available: 30.1GB):\n",
      "- Replay buffer: 80000\n",
      "- Batch size: 64\n",
      "- Frame stack: 4\n",
      "Starting training...\n",
      "Warming up replay buffer (min: 10000)...\n",
      "Starting main training with 10000 samples...\n",
      "Ep    1 | R:  310.0 | Avg R:  310.0 | ε: 0.997 | Steps: 513\n",
      "Ep   10 | R:  190.0 | Avg R:  252.0 | ε: 0.975 | Steps: 5014\n",
      "Ep   20 | R:  350.0 | Avg R:  285.0 | ε: 0.950 | Steps: 10092\n",
      "Ep   30 | R:  640.0 | Avg R:  283.0 | ε: 0.924 | Steps: 15334\n",
      "Ep   40 | R:  280.0 | Avg R:  332.0 | ε: 0.898 | Steps: 20546\n",
      "Ep   50 | R:  240.0 | Avg R:  239.0 | ε: 0.875 | Steps: 25260\n",
      "Ep   60 | R:  220.0 | Avg R:  314.0 | ε: 0.849 | Steps: 30508\n",
      "Ep   70 | R:  120.0 | Avg R:  294.0 | ε: 0.824 | Steps: 35650\n",
      "Ep   80 | R:  210.0 | Avg R:  278.0 | ε: 0.798 | Steps: 40850\n",
      "Ep   90 | R:  120.0 | Avg R:  313.0 | ε: 0.771 | Steps: 46288\n",
      "Saved checkpoint: ./pacman_models/pacman_ep100.keras\n",
      "Ep  100 | R:  170.0 | Avg R:  279.0 | ε: 0.744 | Steps: 51696\n",
      "Ep  110 | R:  230.0 | Avg R:  228.0 | ε: 0.719 | Steps: 56860\n",
      "Ep  120 | R:  150.0 | Avg R:  177.0 | ε: 0.694 | Steps: 61820\n",
      "Ep  130 | R:   40.0 | Avg R:  220.0 | ε: 0.668 | Steps: 67076\n",
      "Ep  140 | R:  330.0 | Avg R:  205.0 | ε: 0.642 | Steps: 72264\n",
      "Ep  150 | R:  150.0 | Avg R:  272.0 | ε: 0.616 | Steps: 77604\n",
      "Ep  160 | R:  150.0 | Avg R:  278.0 | ε: 0.588 | Steps: 83278\n",
      "Ep  170 | R:  430.0 | Avg R:  311.0 | ε: 0.560 | Steps: 88958\n",
      "Ep  180 | R:  160.0 | Avg R:  358.0 | ε: 0.532 | Steps: 94638\n",
      "Ep  190 | R:  490.0 | Avg R:  312.0 | ε: 0.504 | Steps: 100210\n",
      "Saved checkpoint: ./pacman_models/pacman_ep200.keras\n",
      "Ep  200 | R:  420.0 | Avg R:  410.0 | ε: 0.476 | Steps: 105850\n",
      "Ep  210 | R: 1050.0 | Avg R:  498.0 | ε: 0.446 | Steps: 112004\n",
      "Ep  220 | R:  310.0 | Avg R:  525.0 | ε: 0.416 | Steps: 118008\n",
      "Ep  230 | R:  880.0 | Avg R:  478.0 | ε: 0.389 | Steps: 123518\n",
      "Ep  240 | R:  380.0 | Avg R:  682.0 | ε: 0.352 | Steps: 130838\n",
      "Ep  250 | R:  300.0 | Avg R:  541.0 | ε: 0.321 | Steps: 137076\n",
      "Ep  260 | R:  290.0 | Avg R:  599.0 | ε: 0.290 | Steps: 143462\n",
      "Ep  270 | R:  570.0 | Avg R:  657.0 | ε: 0.258 | Steps: 149902\n",
      "Ep  280 | R:  330.0 | Avg R:  511.0 | ε: 0.229 | Steps: 155696\n",
      "Ep  290 | R:  320.0 | Avg R:  665.0 | ε: 0.198 | Steps: 161946\n",
      "Saved checkpoint: ./pacman_models/pacman_ep300.keras\n",
      "Ep  300 | R:  600.0 | Avg R:  731.0 | ε: 0.166 | Steps: 168474\n",
      "Ep  310 | R:  510.0 | Avg R:  659.0 | ε: 0.136 | Steps: 174484\n",
      "Ep  320 | R:  860.0 | Avg R:  790.0 | ε: 0.100 | Steps: 181860\n",
      "Ep  330 | R: 1240.0 | Avg R:  723.0 | ε: 0.067 | Steps: 188520\n",
      "Ep  340 | R:  640.0 | Avg R:  716.0 | ε: 0.036 | Steps: 194718\n",
      "Ep  350 | R:  700.0 | Avg R:  768.0 | ε: 0.010 | Steps: 202114\n",
      "Ep  360 | R:  620.0 | Avg R:  717.0 | ε: 0.010 | Steps: 209138\n",
      "Ep  370 | R:  690.0 | Avg R:  702.0 | ε: 0.010 | Steps: 215444\n",
      "Ep  380 | R:  540.0 | Avg R:  753.0 | ε: 0.010 | Steps: 221882\n",
      "Ep  390 | R: 1100.0 | Avg R:  727.0 | ε: 0.010 | Steps: 228462\n",
      "Saved checkpoint: ./pacman_models/pacman_ep400.keras\n",
      "Ep  400 | R:  830.0 | Avg R:  833.0 | ε: 0.010 | Steps: 236416\n",
      "Ep  410 | R:  340.0 | Avg R: 1028.0 | ε: 0.010 | Steps: 243000\n",
      "Ep  420 | R:  590.0 | Avg R:  643.0 | ε: 0.010 | Steps: 248880\n",
      "Ep  430 | R: 1260.0 | Avg R:  938.0 | ε: 0.010 | Steps: 256364\n",
      "Ep  440 | R:  330.0 | Avg R: 1037.0 | ε: 0.010 | Steps: 263462\n",
      "Ep  450 | R:  570.0 | Avg R:  764.0 | ε: 0.010 | Steps: 269510\n",
      "Ep  460 | R: 1810.0 | Avg R: 1019.0 | ε: 0.010 | Steps: 276648\n",
      "Ep  470 | R: 1630.0 | Avg R:  940.0 | ε: 0.010 | Steps: 283184\n",
      "Ep  480 | R: 2300.0 | Avg R: 1140.0 | ε: 0.010 | Steps: 289874\n",
      "Ep  490 | R:  710.0 | Avg R:  957.0 | ε: 0.010 | Steps: 296280\n",
      "Saved checkpoint: ./pacman_models/pacman_ep500.keras\n",
      "Ep  500 | R:  560.0 | Avg R:  686.0 | ε: 0.010 | Steps: 302618\n",
      "Ep  510 | R:  380.0 | Avg R:  817.0 | ε: 0.010 | Steps: 308766\n",
      "Ep  520 | R:  680.0 | Avg R:  698.0 | ε: 0.010 | Steps: 315098\n",
      "Ep  530 | R:  550.0 | Avg R:  880.0 | ε: 0.010 | Steps: 321746\n",
      "Ep  540 | R:  530.0 | Avg R:  846.0 | ε: 0.010 | Steps: 328370\n",
      "Ep  550 | R: 1070.0 | Avg R:  923.0 | ε: 0.010 | Steps: 335480\n",
      "Ep  560 | R: 1040.0 | Avg R: 1114.0 | ε: 0.010 | Steps: 342700\n",
      "Ep  570 | R:  330.0 | Avg R:  662.0 | ε: 0.010 | Steps: 349260\n",
      "Ep  580 | R:  880.0 | Avg R:  827.0 | ε: 0.010 | Steps: 355224\n",
      "Ep  590 | R:  550.0 | Avg R:  901.0 | ε: 0.010 | Steps: 361784\n",
      "Saved checkpoint: ./pacman_models/pacman_ep600.keras\n",
      "Ep  600 | R:  900.0 | Avg R:  833.0 | ε: 0.010 | Steps: 367416\n",
      "Ep  610 | R: 1360.0 | Avg R:  837.0 | ε: 0.010 | Steps: 373986\n",
      "Ep  620 | R:  500.0 | Avg R:  884.0 | ε: 0.010 | Steps: 380660\n",
      "Ep  630 | R:  590.0 | Avg R:  749.0 | ε: 0.010 | Steps: 386336\n",
      "Ep  640 | R:  430.0 | Avg R:  719.0 | ε: 0.010 | Steps: 391994\n",
      "Ep  650 | R:  660.0 | Avg R: 1033.0 | ε: 0.010 | Steps: 398620\n",
      "Ep  660 | R:  470.0 | Avg R:  892.0 | ε: 0.010 | Steps: 405364\n",
      "Ep  670 | R: 1790.0 | Avg R:  729.0 | ε: 0.010 | Steps: 411196\n",
      "Ep  680 | R:  440.0 | Avg R:  898.0 | ε: 0.010 | Steps: 417026\n",
      "Ep  690 | R:  940.0 | Avg R: 1051.0 | ε: 0.010 | Steps: 423400\n",
      "Saved checkpoint: ./pacman_models/pacman_ep700.keras\n",
      "Ep  700 | R:  670.0 | Avg R: 1052.0 | ε: 0.010 | Steps: 430342\n",
      "Ep  710 | R:  860.0 | Avg R:  750.0 | ε: 0.010 | Steps: 436886\n",
      "Ep  720 | R:  470.0 | Avg R:  975.0 | ε: 0.010 | Steps: 444084\n",
      "Ep  730 | R: 1250.0 | Avg R: 1052.0 | ε: 0.010 | Steps: 450876\n",
      "Ep  740 | R:  600.0 | Avg R:  843.0 | ε: 0.010 | Steps: 456984\n",
      "Ep  750 | R:  870.0 | Avg R:  962.0 | ε: 0.010 | Steps: 463652\n",
      "Ep  760 | R:  620.0 | Avg R:  802.0 | ε: 0.010 | Steps: 469678\n",
      "Ep  770 | R:  890.0 | Avg R:  965.0 | ε: 0.010 | Steps: 476604\n",
      "Ep  780 | R: 2740.0 | Avg R: 1262.0 | ε: 0.010 | Steps: 484266\n",
      "Ep  790 | R:  660.0 | Avg R: 1104.0 | ε: 0.010 | Steps: 490758\n",
      "Saved checkpoint: ./pacman_models/pacman_ep800.keras\n",
      "Ep  800 | R: 1400.0 | Avg R: 1206.0 | ε: 0.010 | Steps: 497308\n",
      "Ep  810 | R:  650.0 | Avg R: 1168.0 | ε: 0.010 | Steps: 504988\n",
      "Ep  820 | R:  860.0 | Avg R:  879.0 | ε: 0.010 | Steps: 511894\n",
      "Ep  830 | R: 1350.0 | Avg R:  974.0 | ε: 0.010 | Steps: 518556\n",
      "Ep  840 | R:  690.0 | Avg R:  977.0 | ε: 0.010 | Steps: 525494\n",
      "Ep  850 | R:  750.0 | Avg R:  990.0 | ε: 0.010 | Steps: 532466\n",
      "Ep  860 | R: 1200.0 | Avg R: 1012.0 | ε: 0.010 | Steps: 539850\n",
      "Ep  870 | R: 1120.0 | Avg R:  931.0 | ε: 0.010 | Steps: 546244\n",
      "Ep  880 | R: 1430.0 | Avg R:  981.0 | ε: 0.010 | Steps: 553212\n",
      "Ep  890 | R: 1110.0 | Avg R: 1120.0 | ε: 0.010 | Steps: 561438\n",
      "Saved checkpoint: ./pacman_models/pacman_ep900.keras\n",
      "Ep  900 | R: 1470.0 | Avg R: 1085.0 | ε: 0.010 | Steps: 568314\n",
      "Ep  910 | R: 1010.0 | Avg R: 1102.0 | ε: 0.010 | Steps: 574856\n",
      "Ep  920 | R:  390.0 | Avg R: 1093.0 | ε: 0.010 | Steps: 581244\n",
      "Ep  930 | R: 1270.0 | Avg R: 1275.0 | ε: 0.010 | Steps: 588680\n",
      "Ep  940 | R: 1890.0 | Avg R: 1089.0 | ε: 0.010 | Steps: 596030\n",
      "Ep  950 | R: 1230.0 | Avg R: 1119.0 | ε: 0.010 | Steps: 603262\n",
      "Ep  960 | R:  650.0 | Avg R: 1160.0 | ε: 0.010 | Steps: 610944\n",
      "Ep  970 | R: 1550.0 | Avg R:  977.0 | ε: 0.010 | Steps: 618322\n",
      "Ep  980 | R: 1560.0 | Avg R:  941.0 | ε: 0.010 | Steps: 625516\n",
      "Ep  990 | R:  900.0 | Avg R:  968.0 | ε: 0.010 | Steps: 632320\n",
      "Saved checkpoint: ./pacman_models/pacman_ep1000.keras\n",
      "Ep 1000 | R: 1450.0 | Avg R:  818.0 | ε: 0.010 | Steps: 638980\n",
      "Saved checkpoint: ./pacman_models/pacman_epfinal.keras\n",
      "\n",
      "Training completed in 307.28 minutes\n",
      "Average reward: 759.9\n",
      "Best reward: 3580.0\n",
      "Saved training plot: ./pacman_models/training_results.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ale_py\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers\n",
    "from collections import deque, namedtuple\n",
    "import random\n",
    "import time\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import psutil\n",
    "\n",
    "class TrainingConfig:\n",
    "    CHECKPOINT_DIR = \"./pacman_models\"\n",
    "    TARGET_UPDATE_FREQ = 1000\n",
    "    TOTAL_EPISODES = 1000\n",
    "    CHECKPOINT_FREQ = 100\n",
    "    MIN_REPLAY_HISTORY = 10000\n",
    "\n",
    "    def __init__(self):\n",
    "        mem = psutil.virtual_memory()\n",
    "        if mem.available > 12 * 1024**3:\n",
    "            self.REPLAY_BUFFER_SIZE = 80000\n",
    "            self.BATCH_SIZE = 64\n",
    "            self.FRAME_STACK_SIZE = 4\n",
    "            self.LEARNING_RATE = 0.00025\n",
    "        else:\n",
    "            self.REPLAY_BUFFER_SIZE = 50000\n",
    "            self.BATCH_SIZE = 32\n",
    "            self.FRAME_STACK_SIZE = 3\n",
    "            self.LEARNING_RATE = 0.0001\n",
    "\n",
    "        self.EPSILON_START = 1.0\n",
    "        self.EPSILON_END = 0.01\n",
    "        self.EPSILON_DECAY_STEPS = 200000\n",
    "        self.GAMMA = 0.99\n",
    "        self.FRAME_SKIP = 4\n",
    "\n",
    "        print(f\"Using configuration (RAM available: {mem.available/1024**3:.1f}GB):\")\n",
    "        print(f\"- Replay buffer: {self.REPLAY_BUFFER_SIZE}\")\n",
    "        print(f\"- Batch size: {self.BATCH_SIZE}\")\n",
    "        print(f\"- Frame stack: {self.FRAME_STACK_SIZE}\")\n",
    "\n",
    "Experience = namedtuple('Experience', ['state', 'action', 'reward', 'next_state', 'done'])\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "class PacManDQN(Model):\n",
    "    def __init__(self, action_size=9):\n",
    "        super().__init__()\n",
    "        self.conv1 = layers.Conv2D(32, (8,8), strides=4, activation='relu')\n",
    "        self.conv2 = layers.Conv2D(64, (4,4), strides=2, activation='relu')\n",
    "        self.conv3 = layers.Conv2D(64, (3,3), strides=1, activation='relu')\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense = layers.Dense(512, activation='relu')\n",
    "        self.output_layer = layers.Dense(action_size, activation='linear')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        os.makedirs(self.config.CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "        self.env = gym.make(\"ALE/MsPacman-v5\",\n",
    "                          render_mode=\"rgb_array\",\n",
    "                          frameskip=self.config.FRAME_SKIP,\n",
    "                          repeat_action_probability=0.0)\n",
    "\n",
    "        self.action_size = self.env.action_space.n\n",
    "        self.online_net = PacManDQN(self.action_size)\n",
    "        self.target_net = PacManDQN(self.action_size)\n",
    "\n",
    "        # Initialize networks\n",
    "        dummy_input = tf.random.normal((1, 88, 80, self.config.FRAME_STACK_SIZE))\n",
    "        _ = self.online_net(dummy_input)\n",
    "        _ = self.target_net(dummy_input)\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.config.LEARNING_RATE)\n",
    "        self.replay_buffer = ReplayBuffer(self.config.REPLAY_BUFFER_SIZE)\n",
    "        self.steps = 0\n",
    "        self.episode_rewards = []\n",
    "\n",
    "        # Epsilon decay\n",
    "        self.epsilon_decay = (self.config.EPSILON_START - self.config.EPSILON_END) / self.config.EPSILON_DECAY_STEPS\n",
    "\n",
    "    def preprocess_frame(self, frame):\n",
    "        \"\"\"Downsample and grayscale frame\"\"\"\n",
    "        frame = frame[1:176:2, ::2]  # Downsample to 88x80\n",
    "        return np.mean(frame, axis=-1, dtype=np.float32) / 255.0\n",
    "\n",
    "    def get_epsilon(self):\n",
    "        return max(self.config.EPSILON_END,\n",
    "                  self.config.EPSILON_START - self.steps * self.epsilon_decay)\n",
    "\n",
    "    def update_target_network(self):\n",
    "        self.target_net.set_weights(self.online_net.get_weights())\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.replay_buffer.add(Experience(state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if random.random() < self.get_epsilon():\n",
    "            return random.randint(0, self.action_size - 1)\n",
    "\n",
    "        q_values = self.online_net(np.expand_dims(state, axis=0))\n",
    "        return np.argmax(q_values.numpy()[0])\n",
    "\n",
    "    def create_initial_state(self, frame):\n",
    "        \"\"\"Create initial state by repeating the first frame\"\"\"\n",
    "        return np.stack([frame] * self.config.FRAME_STACK_SIZE, axis=-1)\n",
    "\n",
    "    def update_state(self, state, new_frame):\n",
    "        \"\"\"Update state by shifting frames and adding new frame\"\"\"\n",
    "        return np.concatenate([state[..., 1:], np.expand_dims(new_frame, axis=-1)], axis=-1)\n",
    "\n",
    "    def train(self):\n",
    "        print(\"Starting training...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Warmup phase\n",
    "        print(f\"Warming up replay buffer (min: {self.config.MIN_REPLAY_HISTORY})...\")\n",
    "        frame, _ = self.env.reset()\n",
    "        frame = self.preprocess_frame(frame)\n",
    "        state = self.create_initial_state(frame)\n",
    "\n",
    "        while len(self.replay_buffer) < self.config.MIN_REPLAY_HISTORY:\n",
    "            action = self.env.action_space.sample()\n",
    "            next_frame, reward, done, _, _ = self.env.step(action)\n",
    "            next_frame = self.preprocess_frame(next_frame)\n",
    "            next_state = self.update_state(state, next_frame)\n",
    "\n",
    "            self.remember(state, action, reward, next_state, done)\n",
    "            if not done:\n",
    "                state = next_state\n",
    "            else:\n",
    "                frame, _ = self.env.reset()\n",
    "                frame = self.preprocess_frame(frame)\n",
    "                state = self.create_initial_state(frame)\n",
    "\n",
    "        print(f\"Starting main training with {len(self.replay_buffer)} samples...\")\n",
    "\n",
    "        for episode in range(1, self.config.TOTAL_EPISODES + 1):\n",
    "            episode_start = time.time()\n",
    "            frame, _ = self.env.reset()\n",
    "            frame = self.preprocess_frame(frame)\n",
    "            state = self.create_initial_state(frame)\n",
    "\n",
    "            total_reward = 0\n",
    "            done = False\n",
    "\n",
    "            while not done:\n",
    "                action = self.act(state)\n",
    "                next_frame, reward, done, _, _ = self.env.step(action)\n",
    "                next_frame = self.preprocess_frame(next_frame)\n",
    "                next_state = self.update_state(state, next_frame)\n",
    "\n",
    "                self.remember(state, action, reward, next_state, done)\n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "                self.steps += 1\n",
    "\n",
    "                if len(self.replay_buffer) >= self.config.BATCH_SIZE and self.steps % 4 == 0:\n",
    "                    self.replay()\n",
    "\n",
    "                if self.steps % self.config.TARGET_UPDATE_FREQ == 0:\n",
    "                    self.update_target_network()\n",
    "\n",
    "            self.episode_rewards.append(total_reward)\n",
    "\n",
    "            if episode % self.config.CHECKPOINT_FREQ == 0:\n",
    "                self.save_checkpoint(episode)\n",
    "                gc.collect()\n",
    "\n",
    "            if episode % 10 == 0 or episode == 1:\n",
    "                avg_reward = np.mean(self.episode_rewards[-10:])\n",
    "                print(f\"Ep {episode:4d} | R: {total_reward:6.1f} | \"\n",
    "                      f\"Avg R: {avg_reward:6.1f} | ε: {self.get_epsilon():.3f} | \"\n",
    "                      f\"Steps: {self.steps}\")\n",
    "\n",
    "        self.save_checkpoint('final')\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\nTraining completed in {total_time/60:.2f} minutes\")\n",
    "        print(f\"Average reward: {np.mean(self.episode_rewards):.1f}\")\n",
    "        print(f\"Best reward: {np.max(self.episode_rewards):.1f}\")\n",
    "        self.plot_training()\n",
    "\n",
    "    def replay(self):\n",
    "        batch = self.replay_buffer.sample(self.config.BATCH_SIZE)\n",
    "        states = np.stack([e.state for e in batch])\n",
    "        actions = np.array([e.action for e in batch])\n",
    "        rewards = np.array([e.reward for e in batch], dtype=np.float32)\n",
    "        next_states = np.stack([e.next_state for e in batch])\n",
    "        dones = np.array([e.done for e in batch], dtype=np.float32)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            current_q = self.online_net(states)\n",
    "            current_action_q = tf.reduce_sum(\n",
    "                current_q * tf.one_hot(actions, self.action_size),\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "            next_q = self.target_net(next_states)\n",
    "            target_q = rewards + (1 - dones) * self.config.GAMMA * tf.reduce_max(next_q, axis=1)\n",
    "\n",
    "            loss = tf.keras.losses.Huber()(target_q, current_action_q)\n",
    "\n",
    "        grads = tape.gradient(loss, self.online_net.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.online_net.trainable_variables))\n",
    "\n",
    "    def save_checkpoint(self, episode):\n",
    "        path = os.path.join(self.config.CHECKPOINT_DIR, f\"pacman_ep{episode}.keras\")\n",
    "        self.online_net.save(path, include_optimizer=False)\n",
    "        print(f\"Saved checkpoint: {path}\")\n",
    "\n",
    "    def plot_training(self):\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.plot(self.episode_rewards)\n",
    "        plt.title(\"Training Progress\")\n",
    "        plt.xlabel(\"Episode\")\n",
    "        plt.ylabel(\"Reward\")\n",
    "\n",
    "        plot_path = os.path.join(self.config.CHECKPOINT_DIR, \"training_results.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\"Saved training plot: {plot_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    try:\n",
    "        import ale_py\n",
    "    except ImportError:\n",
    "        print(\"Installing required packages...\")\n",
    "        import sys\n",
    "        import subprocess\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\",\n",
    "                             \"ale-py\", \"gymnasium\", \"tensorflow\", \"psutil\"])\n",
    "\n",
    "    config = TrainingConfig()\n",
    "    agent = DQNAgent(config)\n",
    "    agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1655427",
   "metadata": {
    "papermill": {
     "duration": 0.006708,
     "end_time": "2025-04-05T22:28:53.684101",
     "exception": false,
     "start_time": "2025-04-05T22:28:53.677393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18464.739944,
   "end_time": "2025-04-05T22:28:57.392363",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-05T17:21:12.652419",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
